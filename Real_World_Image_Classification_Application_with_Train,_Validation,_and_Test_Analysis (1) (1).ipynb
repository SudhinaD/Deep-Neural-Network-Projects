{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Sudhina D\n",
        "\n",
        "Batch: R3\n",
        "\n",
        "Date: 19-02-2023\n",
        "\n",
        "Experiment Name:Real World Image Classification Application with Train, Validation and Test Analysis "
      ],
      "metadata": {
        "id": "xmEaUaWTEhrA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sqnq9vilhC7"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXj4AykPnEjL",
        "outputId": "33d34832-f32a-47da-9539-9768a7d51cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders[full]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8oD7cOLspG7",
        "outputId": "e667ccbc-8b3f-4ecb-ce56-44a11263a7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders[full]\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from split-folders[full]) (4.64.1)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-C036WjHzruQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For making three datasets\n",
        "import splitfolders\n",
        "input_folder='/content/drive/MyDrive/DNNSP LAB/flowers'\n",
        "splitfolders.ratio(input_folder,output=\"datasets\",\n",
        "                  seed=42,ratio=(.7,.2,.1),group_prefix=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QodKdKi7s8hc",
        "outputId": "0fb3681c-5037-4d8f-c033-46a88d979808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2046 files [00:04, 448.46 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf'/content/drive/MyDrive/DNNSP LAB/flowers'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T-2-NN71aDu",
        "outputId": "634b4f9b-540e-4f4b-d9cb-32b4e895becc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: invalid option -- '/'\n",
            "Try 'rm --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess the dataset\n",
        "train_dir = \"/content/datasets/train\"\n",
        "val_dir = \"/content/datasets/val\"\n",
        "test_dir = \"/content/datasets/test\""
      ],
      "metadata": {
        "id": "qeP59kQbnH0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "metadata": {
        "id": "Mnme5kDHoyqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "uTfLF3qNozc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZGd8nuRo2k6",
        "outputId": "9d95b040-1a75-4966-fd50-631a5bc5b2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1430 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "id": "2uye_WXWu2M6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5271c12-ec46-4657-afd8-62ec9f803617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 407 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = val_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "id": "nAInHPXNu8Iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea60033-f325-40f1-bfd9-8cd1b61b73db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 209 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "HKrhOtyLvBLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KkhgQuKGyc2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train the model\n",
        "history = model.fit(train_data,\n",
        "                    validation_data=val_data,\n",
        "                    epochs=10)"
      ],
      "metadata": {
        "id": "z51Cc18yyhBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7909ea74-409e-4ac8-b238-8827b37ec3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "45/45 [==============================] - 33s 471ms/step - loss: 1.3685 - accuracy: 0.6161 - val_loss: 0.7821 - val_accuracy: 0.7224\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.8122 - accuracy: 0.7091 - val_loss: 0.8008 - val_accuracy: 0.7322\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 21s 471ms/step - loss: 0.7459 - accuracy: 0.7399 - val_loss: 0.7167 - val_accuracy: 0.7494\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 22s 482ms/step - loss: 0.7215 - accuracy: 0.7406 - val_loss: 0.7119 - val_accuracy: 0.7666\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 22s 495ms/step - loss: 0.6841 - accuracy: 0.7580 - val_loss: 0.6973 - val_accuracy: 0.7592\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 21s 459ms/step - loss: 0.6369 - accuracy: 0.7664 - val_loss: 0.6375 - val_accuracy: 0.7912\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 22s 492ms/step - loss: 0.6236 - accuracy: 0.7797 - val_loss: 0.6809 - val_accuracy: 0.7617\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 21s 461ms/step - loss: 0.5680 - accuracy: 0.8021 - val_loss: 0.6141 - val_accuracy: 0.7887\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 22s 492ms/step - loss: 0.5476 - accuracy: 0.8035 - val_loss: 0.6248 - val_accuracy: 0.8034\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4981 - accuracy: 0.8105 - val_loss: 0.7330 - val_accuracy: 0.7420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate the model\n",
        "#test_loss, test_acc = model.evaluate(test_data)\n",
        "#print('Test accuracy:', test_acc)\n",
        "model.evaluate(train_data)"
      ],
      "metadata": {
        "id": "RyUFrq2Pylst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1570e08-b271-4ea9-e271-196e0b46bfbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 19s 416ms/step - loss: 0.4732 - accuracy: 0.8329\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4732140600681305, 0.8328671455383301]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Save the model\n",
        "model.save('flower_classification_model.h5')"
      ],
      "metadata": {
        "id": "xYuH3sW7yp4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Load the model for making predictions on new images\n",
        "new_image = '/content/drive/MyDrive/DNNSP LAB/flowers/flower.jfif'\n",
        "new_image_data = tf.keras.preprocessing.image.load_img(new_image, target_size=(224, 224))\n",
        "new_image_data = tf.keras.preprocessing.image.img_to_array(new_image_data)\n",
        "new_image_data = np.expand_dims(new_image_data, axis=0)\n",
        "new_image_data /= 255."
      ],
      "metadata": {
        "id": "ukxQX3cbyu43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('flower_classification_model.h5')\n",
        "prediction = model.predict(new_image_data)\n",
        "class_index = np.argmax(prediction)\n",
        "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "class_label = classes[class_index]\n",
        "print('Prediction:', class_label)"
      ],
      "metadata": {
        "id": "Q8FWkz-dyzKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acad0a76-58dc-4af0-a154-250bd91521d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 251ms/step\n",
            "Prediction: rose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "JlE2OoGVy5_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33081a8d-9fca-4203-985a-cb6525048768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               22151424  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,245,957\n",
            "Trainable params: 22,245,957\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we use the Keras ImageDataGenerator class to preprocess the dataset and create generators for the training, validation, and test sets. We then define a simple convolutional neural network (CNN) architecture and compile the model with the Adam optimizer and categorical cross-entropy loss."
      ],
      "metadata": {
        "id": "4sO6GL90zAFG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01vWEy8uzA7I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}