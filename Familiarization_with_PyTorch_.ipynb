{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMXriofZrTJB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Sudhina D\n",
        "\n",
        "Batch: R3\n",
        "\n",
        "Date: 19-02-2023\n",
        "\n",
        "Experiment Name: Familiarization_with_PyTorch"
      ],
      "metadata": {
        "id": "grlGN0Y6sjtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "\n",
        "PyTorch is an open-source machine learning framework that was developed primarily by Facebook's AI Research team (FAIR). It is built on top of Python, and it is designed to be efficient, flexible, and easy to use.\n",
        "\n",
        "PyTorch provides a number of key features and benefits, including:\n",
        "\n",
        "Dynamic computational graphs: PyTorch's computational graphs are constructed on-the-fly as operations are executed, allowing for greater flexibility in model construction and training.\n",
        "\n",
        "GPU acceleration: PyTorch makes it easy to run computations on GPUs, which can significantly speed up model training and inference.\n",
        "\n",
        "TorchScript: PyTorch's JIT compiler can compile models into TorchScript, a lightweight serialization format that can be used for inference on platforms with limited resources.\n",
        "\n",
        "TorchHub: PyTorch Hub is a library that provides pre-trained models and tools for working with them.\n",
        "\n",
        "Distributed training: PyTorch supports distributed training on multiple GPUs or machines, allowing for the training of large models on large datasets.\n",
        "\n",
        "Dynamic neural networks: PyTorch makes it easy to define and train dynamic neural networks, where the structure of the network can change during training.\n",
        "\n",
        "Here is an example of a simple binary classification problem using PyTorch in Python:"
      ],
      "metadata": {
        "id": "-QAezdFxrVzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FxpvR0BXrXGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random data\n",
        "X = np.random.rand(1000, 10)\n",
        "y = np.random.randint(2, size=1000)"
      ],
      "metadata": {
        "id": "hhwoaKNkrpzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first array X is a 2D array of shape (1000, 10), where each row represents a sample and each column represents a feature. The values in X are generated using NumPy's random.rand function, which returns an array of random numbers between 0 and 1.\n",
        "\n",
        "The second array Y is a 1D array of shape (1000,), where each element is a binary label (0 or 1) for the corresponding sample in X. The values in Y are generated using NumPy's random.randint function, which returns an array of random integers between 0 (inclusive) and 2 (exclusive).\n",
        "\n",
        "Together, these arrays can be used to train and evaluate a binary classification model, such as a logistic regression or a neural network."
      ],
      "metadata": {
        "id": "WBTtBdRBr2cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y).float()"
      ],
      "metadata": {
        "id": "p6F_6xXOryvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "ClaK_Thhr_3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "3e8KpQkOsESf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y.view(-1,1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayOhWAM3sJBf",
        "outputId": "ede382dc-76e9-40ef-b118-b45180388027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.7026\n",
            "Epoch [2/20], Loss: 0.7016\n",
            "Epoch [3/20], Loss: 0.7007\n",
            "Epoch [4/20], Loss: 0.6998\n",
            "Epoch [5/20], Loss: 0.6990\n",
            "Epoch [6/20], Loss: 0.6983\n",
            "Epoch [7/20], Loss: 0.6976\n",
            "Epoch [8/20], Loss: 0.6970\n",
            "Epoch [9/20], Loss: 0.6965\n",
            "Epoch [10/20], Loss: 0.6960\n",
            "Epoch [11/20], Loss: 0.6955\n",
            "Epoch [12/20], Loss: 0.6951\n",
            "Epoch [13/20], Loss: 0.6947\n",
            "Epoch [14/20], Loss: 0.6944\n",
            "Epoch [15/20], Loss: 0.6942\n",
            "Epoch [16/20], Loss: 0.6939\n",
            "Epoch [17/20], Loss: 0.6938\n",
            "Epoch [18/20], Loss: 0.6936\n",
            "Epoch [19/20], Loss: 0.6935\n",
            "Epoch [20/20], Loss: 0.6934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(X)\n",
        "    predicted = (outputs > 0.5).float()\n",
        "    accuracy = (predicted == y.view(-1,1)).float().mean()\n",
        "    print('Test accuracy: {:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgqSnP9WsVEr",
        "outputId": "34167a70-dd7d-4b60-9609-34ac42637d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first generate random data with 1000 samples of 10 features and binary labels. We then convert the data into PyTorch tensors. We define a simple neural network with one hidden layer of 16 units with ReLU activation and an output layer with a single unit with sigmoid activation. We define binary cross-entropy as the loss function and the Adam optimizer. We train the model on the generated data for 10 epochs, and we print the loss at each epoch. Finally, we evaluate the model on the same data and print the test accuracy.\n",
        "\n",
        "PyTorch is a popular deep learning framework that provides an intuitive and flexible way to build and train neural networks. The principles in this example can be extended to more complex classification problems with larger datasets and deeper neural networks."
      ],
      "metadata": {
        "id": "GwIeqfkTsc6f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bz7sQXjesZPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wAyL0XZssiD1"
      }
    }
  ]
}